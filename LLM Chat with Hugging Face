# Updated package installations for better performance and compatibility:
!pip install langchain==0.3.26
!pip install langchain-openai==0.3.28
!pip install langchain-community==0.3.19
!pip install huggingface_hub==0.27.1


!pip install transformers==4.50.0
!pip install langchain_huggingface


from getpass import getpass

OPENAI_KEY = getpass('Enter Open AI API Key: ')


import os

os.environ['OPENAI_API_KEY'] = OPENAI_KEY


from getpass import getpass

HUGGINGFACEHUB_API_TOKEN = getpass('Please enter your HuggingFace Token here: ')


import os

os.environ['HF_TOKEN'] = HUGGINGFACEHUB_API_TOKEN
os.environ['OPENAI_API_KEY'] = OPENAI_KEY


import os
from langchain_openai import ChatOpenAI

# Set your API Key
os.environ["OPENAI_API_KEY"] = OPENAI_KEY

# Use ChatOpenAI for gpt-4o-mini
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)



prompt = """Explain what is Generative AI in 3 bullet points"""
print(prompt)



response = chatgpt.invoke(prompt)
print(response.content)



!pip install -U langchain-google-genai



# 1. Install the package (only needs to be done once per session)
# !pip install -U langchain-google-genai

# 2. Import the library
from langchain_google_genai import ChatGoogleGenerativeAI
import getpass
import os

# 3. Set up your API Key 
# (It's safer to use getpass so your key isn't visible in the code)
if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Google API Key:AIzaSyBOkhLuh4Tn5MasFJiqND-umW0DC8zoEQ8")

# 4. Initialize and Invoke
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
response = llm.invoke("Hello, are you working now?")

print(response.content)




response = chatgpt.invoke(prompt)
print(response.content)




from langchain_google_genai import ChatGoogleGenerativeAI
import os

# 1. Define the model (Make sure your API Key is set here)
# Replace 'YOUR_KEY_HERE' with your actual API key
chatgpt = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key="AIzaSyBOkhLuh4Tn5MasFJiqND-umW0DC8zoEQ8"
)

prompt = "Hello! Are you configured correctly?"

# 3. NOW you can call it
response = chatgpt.invoke(prompt)

# 4. Print the result
print(response.content)



import os
from langchain_openai import ChatOpenAI


# Use ChatOpenAI for gpt-4o-mini
llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)



prompt = """Explain what is Generative AI in 3 bullet points"""
print(prompt)



response = chatgpt.invoke(prompt)
response



print(response.content)






